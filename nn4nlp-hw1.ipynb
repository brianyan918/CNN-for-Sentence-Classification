{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nn4nlp-hw1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pRrJRbFuN7u5","colab_type":"text"},"source":["**CNN FOR SENTENCE CLASSIFICATION**\n","\n","Author: Brian Yan\n","\n","The task of this model is to classify sentences into 16 different genres, ranging from video games to music.\n","\n","The approach is to use a convolution layer to extract n-gram features of varying lengths. These features are then passed through a fully connected layer. Altogether, this CNN has 2 layers and achieves 88% accuracy on the validation set.\n","\n","Individually trained models trained this way can achieve between 84-86% accuracy with optimal early stopping. If several of these models are ensembled together using a majority voting scheme, then an additional 2-4% boost is achieved.\n","\n","This implementation references Yoon Kim's paper as a baseline: https://arxiv.org/pdf/1408.5882.pdf\n","\n","Second source for CNN model code in PyTorch is Graham Neubig's course sample code: https://github.com/neubig/nn4nlp-code/tree/master/05-cnn-pytorch"]},{"cell_type":"code","metadata":{"id":"SQeKzsopQnTs","colab_type":"code","colab":{}},"source":["## Run this code for Google Colab to ensure a high ram environment is provisioned\n","\n","# a = []\n","# while(1):\n","#     a.append('1')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYLRyryOlpi0","colab_type":"code","colab":{}},"source":["version = '/m5'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w0iOMRQu-ExS","colab_type":"text"},"source":["**SETUP**\n","\n","Packages, drive mounting, and data loading"]},{"cell_type":"code","metadata":{"id":"HiYfXKnI-GIb","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import sys\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils import data\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","\n","import matplotlib.pyplot as plt\n","import time\n","\n","import pickle"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z5OijO0pxkm5","colab_type":"code","outputId":"93a0dadd-3368-4a8a-d748-f72157c8e706","executionInfo":{"status":"ok","timestamp":1580924026424,"user_tz":300,"elapsed":329,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CK8sONjt-DEC","colab_type":"code","colab":{}},"source":["root_path = '/content/gdrive/My Drive/CNN for Sentence Classification'  #change dir to your project folder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ta9io_E7Go3-","colab_type":"code","colab":{}},"source":["def txt_to_npy(file):\n","    with open(file, 'r') as f:\n","        lines = f.readlines()\n","        x = []\n","        y = []\n","        for line in lines:\n","            tmp = line.split(' ||| ')\n","            x_tmp = tmp[1].replace(' @-@ ', '-')\n","            x_tmp = x_tmp.replace(' @.@ ', '.')\n","            x_tmp = x_tmp.replace(' @,@ ', ',')\n","            x.append(x_tmp.strip('\\n'))\n","            y.append(tmp[0])\n","    return np.array(x), np.array(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NiM0kpRIIpOO","colab_type":"code","outputId":"bba369b9-3c2e-4d6d-836a-2d11d55a48f0","executionInfo":{"status":"ok","timestamp":1580924029737,"user_tz":300,"elapsed":1793,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["val_x, val_y = txt_to_npy(root_path+\"/topicclass_valid.txt\")\n","print(len(val_x), len(val_y))\n","train_x, train_y = txt_to_npy(root_path+\"/topicclass_train.txt\")\n","print(len(train_x), len(train_y))\n","test_x, _ = txt_to_npy(root_path+\"/topicclass_test.txt\")\n","print(len(test_x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["643 643\n","253909 253909\n","697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nze8l2kE-Sky","colab_type":"code","outputId":"51097853-afad-4f80-8d66-d70bd3e255ac","executionInfo":{"status":"ok","timestamp":1580924029737,"user_tz":300,"elapsed":1073,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cuda = torch.cuda.is_available()\n","cuda"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"Wjnuy0dQMccc","colab_type":"text"},"source":["**WORD EMBEDDINGS**\n","\n","Pre-trained word embeddings from FastText (a FB project) are used in the CNN. These embeddings are kept static during training, which is a decision made to ensure greater generalization. The task-specific corpus is more narrow and thus training word embeddings on these result in poorer performance.\n","\n","Note: an unexplored option is to combine static and newly trained word embeddings, either through a multiplication filter or through addition."]},{"cell_type":"code","metadata":{"id":"EkruhsMlL22C","colab_type":"code","colab":{}},"source":["## This code is used to load the full FastText word embeddings from text, which is a 2 GB file available on their website\n","## Do not need to run this code if the myftvec.p pickle file is available; that is a smaller version of the relevant words to this task\n","\n","# def load_vocab(file_list):\n","#     vocab = set()\n","#     for file in file_list:\n","#         with open(file, 'r') as f:\n","#             lines = f.readlines()\n","#             for line in lines:\n","#                 tmp = line.split(' ||| ')\n","#                 words = tmp[1].split(\" \")\n","#                 for w in words:\n","#                     vocab.add(w)\n","#     return vocab\n","\n","# vocab = load_vocab([root_path+\"/topicclass_test.txt\", root_path+\"/topicclass_train.txt\", root_path+\"/topicclass_valid.txt\"])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVBPpxyT_jRh","colab_type":"code","colab":{}},"source":["# def load_vectors(file_name):\n","#     ft_vectors = {}\n","#     with open(file_name, 'r') as f:\n","#         metadata = f.readline().split(' ')          #n lines, vec size\n","#         for i in range(int(metadata[0]) // 2):      #read half of the file\n","#             line = f.readline().split(' ')\n","#             word = line[0]\n","#             vec = np.array(line[1:],dtype=float)\n","#             ft_vectors[word] = vec\n","#     return ft_vectors\n","\n","# ft_vectors = load_vectors(root_path+\"/wiki-news-300d-1M.vec\")\n","# print(len(ft_vectors))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3l4-7TQB_MWK","colab_type":"code","colab":{}},"source":["# my_ft_vectors = {}\n","# for word in vocab:\n","#     if word in ft_vectors.keys():\n","#         my_ft_vectors[word] = ft_vectors[word]\n","\n","# pickle.dump(my_ft_vectors, open(root_path+\"/myftvec.p\", \"wb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RgniUS9nfrpK","colab_type":"code","colab":{}},"source":["# print(len(my_ft_vectors))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ObSqi9WVnBg2","colab_type":"code","colab":{}},"source":["## Run from here if already saved pickle previously\n","\n","my_ft_vectors = pickle.load(open(root_path+\"/myftvec.p\", \"rb\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AC5yNDyFZcFb","colab_type":"code","outputId":"3c30b748-23e5-416a-bff8-b404aecd71fe","executionInfo":{"status":"ok","timestamp":1580924047175,"user_tz":300,"elapsed":543,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["we_len = my_ft_vectors['the'].shape[0]\n","print(we_len)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BxcEfIPYsA67","colab_type":"code","colab":{}},"source":["## unknown word resolution. Ultimately, use 0 vector if the word is unrecognized\n","\n","def unk_we(word, vecs):\n","    if word.lower() in vecs:\n","        return vecs[word.lower()]\n","    elif word.upper() in vecs:\n","        return vecs[word.upper()]\n","    else:\n","        return np.zeros(we_len) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tTiVMNQ_-oKi","colab_type":"text"},"source":["**DATA LOADER**"]},{"cell_type":"code","metadata":{"id":"mmLmHTl3-U4z","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, Dataset, TensorDataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LaAuLQsjVZtl","colab_type":"code","colab":{}},"source":["def to_tensor(numpy_array):\n","    return torch.from_numpy(numpy_array).float()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwHHOIG_hAA5","colab_type":"code","colab":{}},"source":["## This code is used to generate the list of classes below\n","\n","# classes = set()\n","# for c in val_y:\n","#     classes.add(c)\n","# print(len(classes))\n","# for c in train_y:\n","#     classes.add(c)\n","# print(len(classes))\n","# classes = list(classes)\n","# classes.sort()\n","# print(classes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yNvyi79Vr2je","colab_type":"code","colab":{}},"source":["classes = ['Agriculture, food and drink', 'Art and architecture', \n","           'Engineering and technology', 'Geography and places', \n","           'History', 'Language and literature', \n","           'Mathematics', 'Media and drama', \n","           'Miscellaneous', 'Music', \n","           'Natural sciences', 'Philosophy and religion', \n","           'Social sciences and society', 'Sports and recreation', \n","           'Video games', 'Warfare']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ok6bZl0bqpfp","colab_type":"code","colab":{}},"source":["## class number given the string\n","\n","def class_id(y):\n","    return classes.index(y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mVqDHSosx_C","colab_type":"code","colab":{}},"source":["## word embedding vector given the string\n","\n","def word_embedding(x, vecs):\n","    words = x.split(' ')\n","    we = np.empty((len(words), we_len))\n","    for i, word in enumerate(words):\n","        if word in vecs:\n","            we[i] = vecs[word]\n","        else: \n","            we[i] = unk_we(word, vecs)\n","    return we"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OWj1S1w5-mw0","colab_type":"code","colab":{}},"source":["## custom dataset class\n","\n","class myDataset(Dataset):\n","    def __init__(self, x, y):\n","        self.x_list = x\n","        self.y_list = y\n","\n","    def __getitem__(self, idx):\n","        xi = to_tensor(word_embedding(self.x_list[idx], my_ft_vectors))\n","        xi.requires_grad = False\n","        yi = -1 if self.y_list is None else class_id(self.y_list[idx])\n","        return xi, yi\n","\n","    def __len__(self):\n","        return len(self.x_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXggHpYBpcxt","colab_type":"code","colab":{}},"source":["## custom collate fxn, which pads sentences in batch to the same length; necessary for CNN operations\n","\n","from torch.nn.utils.rnn import pad_sequence\n","def collate(batch):\n","    x_batch = [item[0] for item in batch]\n","    y_batch = [item[1] for item in batch]\n","    return pad_sequence(x_batch, batch_first=True, padding_value=0.0), np.array(y_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLlHJbbeLEK3","colab_type":"code","colab":{}},"source":["train_data = myDataset(train_x, train_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceqNuFa9LLGi","colab_type":"code","colab":{}},"source":["val_data = myDataset(val_x, val_y)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2JuXYKSLP8O","colab_type":"code","colab":{}},"source":["test_data = myDataset(test_x, None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lPYWCrpSLqRa","colab_type":"code","colab":{}},"source":["## data loader class definitions\n","\n","num_workers = 8 if cuda else 0\n","train_loader_args = dict(shuffle=True, batch_size=64, num_workers=num_workers, pin_memory=True, collate_fn=collate) if cuda\\\n","                    else dict(shuffle=True, batch_size=64, collate_fn=collate)\n","train_loader = data.DataLoader(train_data, **train_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7tjXiW3LMAH_","colab_type":"code","colab":{}},"source":["val_loader_args = dict(shuffle=True, batch_size=64, num_workers=num_workers, pin_memory=True, collate_fn=collate) if cuda\\\n","                    else dict(shuffle=True, batch_size=64, collate_fn=collate)\n","val_loader = data.DataLoader(val_data, **val_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKcZRPnhvH97","colab_type":"code","outputId":"da1ccac5-50f9-4c7e-8d21-a7f5d3fc4b93","executionInfo":{"status":"ok","timestamp":1580923590081,"user_tz":300,"elapsed":11381,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["## testing of speed; data loading can be a training time bottleneck where GPU waits for CPU\n","\n","%%timeit\n","for epoch in range(1):\n","    #print(\"Epoch\", epoch)\n","    for x_batch, y_batch in val_loader:\n","          # print(len(x_batch), len(x_batch[0]))\n","          # print(len(y_batch), y_batch)\n","          break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The slowest run took 21.23 times longer than the fastest. This could mean that an intermediate result is being cached.\n","1 loop, best of 3: 454 ms per loop\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sW4OH74_gQUc","colab_type":"code","outputId":"3d84106c-af36-4db5-e450-43e0cde9f3c6","executionInfo":{"status":"ok","timestamp":1580923621316,"user_tz":300,"elapsed":2093,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"12562350992992059122"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["%%timeit\n","val_data.__getitem__(1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The slowest run took 44.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n","10000 loops, best of 3: 41.2 µs per loop\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BeuicYsFiOv_","colab_type":"text"},"source":["**MODEL**\n","\n","Model definition, which is 2 layers: convolution and fully connected. The convolution layer is designed to be variable given an input, such that different filter sizes and number of filters can be used. Different filter sizes are concatenated after being activated in ReLu.\n","\n","While batch norm is always on, dropout can be toggled. Max pooling is chosen as the pooling operation."]},{"cell_type":"code","metadata":{"id":"ZJKre5_blkxg","colab_type":"code","colab":{}},"source":["save_path = root_path + version+ \".pt\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bJLrNZRLgQ3_","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNNclass(torch.nn.Module):\n","    def __init__(self, emb_size, num_filters, window_sizes, ntags, dropout=False):\n","        super(CNNclass, self).__init__()\n","\n","        self.dropout = dropout\n","        self.n_windows = len(window_sizes)\n","\n","        #Convolution filters by length\n","        self.convs = nn.ModuleList(nn.Sequential(nn.Conv1d(in_channels=emb_size, out_channels=num_filters, kernel_size=win,\n","                                                stride=1, padding=2, dilation=1, groups=1, bias=True),\n","                                              nn.BatchNorm1d(num_filters),\n","                                              torch.nn.ReLU()) for win in window_sizes)\n","\n","        self.projection_layer = torch.nn.Linear(in_features=num_filters*self.n_windows, out_features=ntags, bias=True)\n","        torch.nn.init.xavier_uniform_(self.projection_layer.weight)\n","\n","    def forward(self, emb):\n","        emb = emb.permute(0, 2, 1)\n","\n","        # Convolutions, batch norm, relu\n","        h_list = [conv(emb) for conv in self.convs]     # 1 x num_filters x nwords\n","\n","        # Do max pooling\n","        h_list = [h.max(dim=2)[0] for h in h_list]      # 1 x num_filters\n","\n","        h = torch.cat(h_list, dim=1)                    #1 x (3 x num_filters)\n","\n","        if self.dropout:\n","            h = F.dropout(h, p=.2)\n","\n","        out = self.projection_layer(h)                  # size(out) = 1 x ntags\n","\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wypzc6C7h01V","colab_type":"code","outputId":"68462efc-86e8-4355-8bd0-ae86bbc85570","executionInfo":{"status":"ok","timestamp":1580878182410,"user_tz":300,"elapsed":1234,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"11896960355749703790"}},"colab":{"base_uri":"https://localhost:8080/","height":353}},"source":["# # This is the baseline model from the paper: https://arxiv.org/pdf/1408.5882.pdf\n","# # Reaches 81-84%, with early stopping\n","\n","# EMB_SIZE = we_len\n","# N_FILTERS = 100\n","# WIN_SIZES = [2, 3, 4]\n","# N_TAGS = len(classes)\n","# DROP = True\n","\n","# # initialize the model\n","# model = CNNclass(EMB_SIZE, N_FILTERS, WIN_SIZES, N_TAGS, DROP)\n","# model.cuda()\n","# device = torch.device(\"cuda\" if cuda else \"cpu\")\n","# model.to(device)\n","# criterion = torch.nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(model.parameters())\n","\n","# print(model, device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 1000, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 1000, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 1000, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=3000, out_features=16, bias=True)\n",") cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DliYYNGImuY4","colab_type":"code","colab":{}},"source":["## uncomment this to load a saved model\n","\n","#model.load_state_dict(torch.load(save_path))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yR7Sa9cCs6_r","colab_type":"text"},"source":["**TRAIN**"]},{"cell_type":"code","metadata":{"id":"xBIzsUHnoyhL","colab_type":"code","colab":{}},"source":["## training procedure\n","\n","def train_model(model, loader, criterion, optimizer, device):\n","    \n","    # Perform training\n","    model.train()\n","\n","    running_loss = 0.0\n","    train_correct = 0.0\n","    start = time.time()\n","\n","    for batch_idx, (words, target) in enumerate(loader): \n","        words = words.to(device)\n","        target = to_tensor(target).to(device)\n","        \n","        outputs = model(words)\n","        loss = criterion(outputs, target.long())\n","        running_loss += loss.item()\n","        \n","        # Do back-prop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    end = time.time()\n","    running_loss /= len(train_loader)\n","    print('Training Loss: ', running_loss, 'Time: ', end - start, 's')\n","    \n","    #torch.save(model.state_dict(), save_path)\n","    return running_loss"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxlpWMpGrvIC","colab_type":"code","colab":{}},"source":["## testing procedure\n","\n","def test_model(model, loader, criterion, device):\n","    with torch.no_grad():\n","        model.eval()\n","\n","        running_loss = 0.0\n","        total_predictions = 0.0\n","        correct_predictions = 0.0\n","\n","        for batch_idx, (words, target) in enumerate(loader):   \n","            words = words.to(device)\n","            target = to_tensor(target).to(device)\n","\n","            outputs = model(words)\n","\n","            _, predicted = torch.max(outputs.data, 1)\n","            total_predictions += target.size(0)\n","            correct_predictions += (predicted == target).sum().item()\n","\n","            loss = criterion(outputs, target.long())\n","            running_loss += loss.item()\n","\n","\n","        running_loss /= len(loader)\n","        acc = (correct_predictions/total_predictions)*100.0\n","        print('Testing Loss: ', running_loss)\n","        print('Testing Accuracy: ', acc, '%')\n","        return running_loss, acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tJNfYaYCiJDO","colab_type":"code","colab":{}},"source":["## Basic training for 1 model. Commented out in favor of ensembled training, which follows below.\n","\n","# for ITER in range(10):\n","#     train_model(model, train_loader, criterion, optimizer, device)\n","#     test_model(model, val_loader, criterion, device)\n","#     print('='*20)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObgBMvg0jRBl","colab_type":"text"},"source":["**TEST**\n","\n","This section is used to generate accuracies and labels for single models. Commented out in favor of ensembled method below."]},{"cell_type":"code","metadata":{"id":"4Wpqr29hjSRZ","colab_type":"code","colab":{}},"source":["## Prediction for a single model\n","\n","# def predict(model, loader, out_file):\n","#     with torch.no_grad():\n","#         model.eval()\n","\n","#         with open(out_file, \"w\") as f:\n","#             for batch_idx, (words, target) in enumerate(loader):\n","#                 outputs = model(words.to(device))\n","#                 _, predicted = torch.max(outputs.data, 1)\n","#                 f.write(classes[predicted.cpu().numpy()[0]]+'\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CGglWxQomNLW","colab_type":"code","colab":{}},"source":["# pred_loader_args = dict(shuffle=False, batch_size=1, num_workers=0, pin_memory=True, collate_fn=collate) if cuda\\\n","#                     else dict(shuffle=False, batch_size=1, collate_fn=collate)\n","# pred_loader = data.DataLoader(val_data, **pred_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Mp2cm3Zk5Qa","colab_type":"code","colab":{}},"source":["# predict(model, pred_loader, root_path+\"/val.txt\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QjOXGt1-EGmO","colab_type":"text"},"source":["**ENSEMBLING**\n","\n","The ensembling method that follows is the main contribution of this project that is incremental to the baseline provided in the Yoon Kim paper. \n","\n","The procedure relies on a hyperparameter controller, which makes random pertubations to the model architecture within a defined search space: filter number, kernel sizes, number of kernel types, and dropout. These models must pass a defined threshold, set at 84%, in order to be considered in the majority voting ensembling method.\n","\n","The result is a significant boost in accuracy beyond the baseline implementation. One key to this method is the implementation of early stopping. The chosen process is to terminate learning after an epoch decreases the validation accuracy. The model parameters from the previous epoch (which achieved the max observed accuracy) is used."]},{"cell_type":"code","metadata":{"id":"VBOHzsUtEF6M","colab_type":"code","colab":{}},"source":["import random\n","\n","# Hyper-param pertubations, which randomly generates within a defined search space\n","# Return whether model passes the baseline\n","# 1. number of window sizes\n","# 2. number of filters\n","# 3. window sizes\n","# 4. dropout\n","def model_generator(device):\n","    EMB_SIZE = we_len\n","    N_FILTERS = random.randint(150, 400)\n","    WIN_TYPES = random.choice([1, 2, 3, 4])\n","    WIN_START = random.choice([1, 2, 3])\n","    WIN_SIZES = [WIN_START + i + random.choice([0,1,2,3]) for i in range(WIN_TYPES)]\n","    N_TAGS = len(classes)\n","    DROP = random.choice([True, False])\n","\n","    print('*'*40)\n","    params = \"N_FILTERS=\" + str(N_FILTERS) + \" | WIN_SIZES=\" + str(WIN_SIZES) + \" | DROP=\" + str(DROP)\n","    print(params)\n","\n","    # initialize the model\n","    model = CNNclass(EMB_SIZE, N_FILTERS, WIN_SIZES, N_TAGS, DROP)\n","    model.cuda()\n","    model.to(device)\n","    \n","    print(model, device)\n","    print('*'*40)\n","\n","    return model, params\n","\n","# Ensemble n of N models which pass the baseline accuracy\n","def ensemble_controller(num_models, baseline_acc, path):\n","    ensemble_models = []\n","    for i in range(num_models):\n","        model_name = \"e\"+str(i)\n","        print(\"THIS IS: \"+ model_name)\n","        save_path = path + model_name\n","\n","        device = torch.device(\"cuda\" if cuda else \"cpu\")\n","        model, params = model_generator(device)\n","\n","        acc = 0\n","        \n","\n","        for ITER in range(10):\n","            criterion = torch.nn.CrossEntropyLoss()\n","            optimizer = torch.optim.Adam(model.parameters())\n","\n","            train_loss = train_model(model, train_loader, criterion, optimizer, device)\n","            test_loss, test_acc = test_model(model, val_loader, criterion, device)\n","            \n","            # early stopping condition\n","            if test_acc < acc:\n","                break\n","            else:\n","                acc = test_acc\n","                torch.save(model.state_dict(), save_path)\n","            print('='*20)\n","\n","        model.load_state_dict(torch.load(save_path))\n","        if acc > baseline_acc:\n","            ensemble_models.append((model, acc, params, save_path))\n","            print(model_name+\" has passed the threshold, achieving: \" + str(acc) + \"%\")\n","            with open(path+'ensemble_log.txt', 'a') as f:\n","                f.write(str(i) + \" | \" + str(acc) + \" | \" + params) + '\\n'\n","\n","        print(\"-\")\n","\n","    return ensemble_models"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"blnbUlZv1Na4","colab_type":"code","colab":{}},"source":["ensemble_group = \"/models3/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7JIXg7LEneHX","colab_type":"code","outputId":"15c6eea6-22fe-4aad-bd79-221938143fca","executionInfo":{"status":"ok","timestamp":1580882128667,"user_tz":300,"elapsed":1379601,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"11896960355749703790"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["ensemble_models = ensemble_controller(15, 85, root_path + ensemble_group)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["THIS IS: e0\n","****************************************\n","N_FILTERS=271 | WIN_SIZES=[3, 3, 6] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 271, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(271, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 271, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(271, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 271, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(271, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=813, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.7978225373813221 Time:  31.0920672416687 s\n","Testing Loss:  0.5085972520438108\n","Testing Accuracy:  84.60342146189736 %\n","====================\n","Training Loss:  0.6040705651412869 Time:  30.639312505722046 s\n","Testing Loss:  0.47261796485293994\n","Testing Accuracy:  85.69206842923795 %\n","====================\n","Training Loss:  0.4592790181726037 Time:  31.185970544815063 s\n","Testing Loss:  0.4689004990187558\n","Testing Accuracy:  85.06998444790047 %\n","e0 has passed the threshold, achieving: 85.69206842923795%\n","-\n","THIS IS: e1\n","****************************************\n","N_FILTERS=227 | WIN_SIZES=[1] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 227, kernel_size=(1,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(227, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=227, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.7949827419323546 Time:  22.031169652938843 s\n","Testing Loss:  0.5713509131561626\n","Testing Accuracy:  83.51477449455676 %\n","====================\n","Training Loss:  0.6575381567761782 Time:  21.99210810661316 s\n","Testing Loss:  0.569126305255023\n","Testing Accuracy:  83.51477449455676 %\n","====================\n","Training Loss:  0.6028603960482043 Time:  22.764283418655396 s\n","Testing Loss:  0.6173570156097412\n","Testing Accuracy:  83.04821150855366 %\n","-\n","THIS IS: e2\n","****************************************\n","N_FILTERS=230 | WIN_SIZES=[2, 2, 6] | DROP=True\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 230, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 230, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 230, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=690, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8676465219562693 Time:  29.30653476715088 s\n","Testing Loss:  0.6528133641589772\n","Testing Accuracy:  82.42612752721618 %\n","====================\n","Training Loss:  0.668549723457545 Time:  29.551307201385498 s\n","Testing Loss:  0.5019114929653535\n","Testing Accuracy:  82.73716951788491 %\n","====================\n","Training Loss:  0.5597960531501279 Time:  29.19991421699524 s\n","Testing Loss:  0.4830621237104589\n","Testing Accuracy:  86.31415241057543 %\n","====================\n","Training Loss:  0.46801447789485173 Time:  29.619678497314453 s\n","Testing Loss:  0.5316433053125035\n","Testing Accuracy:  82.42612752721618 %\n","e2 has passed the threshold, achieving: 86.31415241057543%\n","-\n","THIS IS: e3\n","****************************************\n","N_FILTERS=324 | WIN_SIZES=[3] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 324, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(324, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=324, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.7742571459722615 Time:  22.21129536628723 s\n","Testing Loss:  0.5056103115732019\n","Testing Accuracy:  84.13685847589424 %\n","====================\n","Training Loss:  0.6126668877944711 Time:  22.231937408447266 s\n","Testing Loss:  0.5127684541723945\n","Testing Accuracy:  83.67029548989113 %\n","-\n","THIS IS: e4\n","****************************************\n","N_FILTERS=260 | WIN_SIZES=[1, 3, 4] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 260, kernel_size=(1,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 260, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 260, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(260, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=780, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.792761504424796 Time:  29.068824529647827 s\n","Testing Loss:  0.49257543750784616\n","Testing Accuracy:  85.8475894245723 %\n","====================\n","Training Loss:  0.6048731926167684 Time:  29.491284132003784 s\n","Testing Loss:  0.5246624702757056\n","Testing Accuracy:  83.20373250388803 %\n","e4 has passed the threshold, achieving: 85.8475894245723%\n","-\n","THIS IS: e5\n","****************************************\n","N_FILTERS=212 | WIN_SIZES=[4] | DROP=True\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 212, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(212, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=212, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8811452216994498 Time:  22.204314470291138 s\n","Testing Loss:  0.5942550978877328\n","Testing Accuracy:  82.42612752721618 %\n","====================\n","Training Loss:  0.6908854898741289 Time:  22.34108304977417 s\n","Testing Loss:  0.5216786969791759\n","Testing Accuracy:  83.98133748055989 %\n","====================\n","Training Loss:  0.6148935358881229 Time:  22.63846516609192 s\n","Testing Loss:  0.5051905878565528\n","Testing Accuracy:  84.75894245723173 %\n","====================\n","Training Loss:  0.5581216801355984 Time:  22.321343660354614 s\n","Testing Loss:  0.5231714861636813\n","Testing Accuracy:  83.20373250388803 %\n","-\n","THIS IS: e6\n","****************************************\n","N_FILTERS=388 | WIN_SIZES=[5, 6] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 388, kernel_size=(5,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(388, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 388, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(388, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=776, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.817562360158791 Time:  29.26838183403015 s\n","Testing Loss:  0.556080399589105\n","Testing Accuracy:  83.67029548989113 %\n","====================\n","Training Loss:  0.6168164269653179 Time:  28.86401391029358 s\n","Testing Loss:  0.4689029816707427\n","Testing Accuracy:  84.13685847589424 %\n","====================\n","Training Loss:  0.4544373115528405 Time:  29.170134782791138 s\n","Testing Loss:  0.4749311689626087\n","Testing Accuracy:  84.75894245723173 %\n","====================\n","Training Loss:  0.29290723906747335 Time:  28.960766792297363 s\n","Testing Loss:  0.6454486284743656\n","Testing Accuracy:  80.248833592535 %\n","-\n","THIS IS: e7\n","****************************************\n","N_FILTERS=326 | WIN_SIZES=[3, 5, 5, 8] | DROP=True\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 326, kernel_size=(3,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 326, kernel_size=(5,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 326, kernel_size=(5,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv1d(300, 326, kernel_size=(8,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(326, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=1304, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.9182593973218313 Time:  42.39929246902466 s\n","Testing Loss:  0.5034519190138037\n","Testing Accuracy:  82.42612752721618 %\n","====================\n","Training Loss:  0.6876576863334424 Time:  42.261699199676514 s\n","Testing Loss:  0.49548452821644867\n","Testing Accuracy:  85.53654743390358 %\n","====================\n","Training Loss:  0.5481406243991167 Time:  42.30466675758362 s\n","Testing Loss:  0.4589593428271738\n","Testing Accuracy:  83.98133748055989 %\n","e7 has passed the threshold, achieving: 85.53654743390358%\n","-\n","THIS IS: e8\n","****************************************\n","N_FILTERS=198 | WIN_SIZES=[6] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 198, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(198, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=198, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.7939498283404617 Time:  22.760027647018433 s\n","Testing Loss:  0.4867213449694894\n","Testing Accuracy:  83.98133748055989 %\n","====================\n","Training Loss:  0.634465241162557 Time:  22.404651641845703 s\n","Testing Loss:  0.522212465717034\n","Testing Accuracy:  82.27060653188181 %\n","-\n","THIS IS: e9\n","****************************************\n","N_FILTERS=168 | WIN_SIZES=[2, 2, 6] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 168, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 168, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 168, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=504, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.7746883135687019 Time:  29.575408697128296 s\n","Testing Loss:  0.4920914701440118\n","Testing Accuracy:  85.53654743390358 %\n","====================\n","Training Loss:  0.6041770572811666 Time:  29.144241333007812 s\n","Testing Loss:  0.4997798096049916\n","Testing Accuracy:  83.04821150855366 %\n","e9 has passed the threshold, achieving: 85.53654743390358%\n","-\n","THIS IS: e10\n","****************************************\n","N_FILTERS=211 | WIN_SIZES=[4, 2, 4] | DROP=True\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 211, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(211, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 211, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(211, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 211, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(211, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=633, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8679421988481115 Time:  29.866557121276855 s\n","Testing Loss:  0.49907095662572165\n","Testing Accuracy:  83.20373250388803 %\n","====================\n","Training Loss:  0.6679978976965011 Time:  29.667993783950806 s\n","Testing Loss:  0.6007858650250868\n","Testing Accuracy:  81.64852255054433 %\n","-\n","THIS IS: e11\n","****************************************\n","N_FILTERS=192 | WIN_SIZES=[1, 2, 6, 6] | DROP=True\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 192, kernel_size=(1,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 192, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 192, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv1d(300, 192, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=768, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8683950052776884 Time:  33.68471693992615 s\n","Testing Loss:  0.53373138200153\n","Testing Accuracy:  83.04821150855366 %\n","====================\n","Training Loss:  0.668108974594713 Time:  33.313868284225464 s\n","Testing Loss:  0.5458793179555372\n","Testing Accuracy:  84.75894245723173 %\n","====================\n","Training Loss:  0.5581796967139047 Time:  33.732481718063354 s\n","Testing Loss:  0.5098871669986031\n","Testing Accuracy:  84.29237947122861 %\n","-\n","THIS IS: e12\n","****************************************\n","N_FILTERS=263 | WIN_SIZES=[4, 4, 7, 9] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 263, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(263, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 263, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(263, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 263, kernel_size=(7,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(263, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv1d(300, 263, kernel_size=(9,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(263, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=1052, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8273692224400058 Time:  38.83453154563904 s\n","Testing Loss:  0.49477205357768317\n","Testing Accuracy:  83.67029548989113 %\n","====================\n","Training Loss:  0.6151246100048264 Time:  38.924163579940796 s\n","Testing Loss:  0.5034245171330192\n","Testing Accuracy:  86.93623639191291 %\n","====================\n","Training Loss:  0.4406330044355033 Time:  39.32978367805481 s\n","Testing Loss:  0.5544477179646492\n","Testing Accuracy:  82.89269051321928 %\n","e12 has passed the threshold, achieving: 86.93623639191291%\n","-\n","THIS IS: e13\n","****************************************\n","N_FILTERS=206 | WIN_SIZES=[4, 7, 6, 6] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 206, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 206, kernel_size=(7,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 206, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv1d(300, 206, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(206, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=824, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8220178308491144 Time:  35.76427602767944 s\n","Testing Loss:  0.6303634670647708\n","Testing Accuracy:  81.18195956454122 %\n","====================\n","Training Loss:  0.6173309194742732 Time:  36.07900023460388 s\n","Testing Loss:  0.5383060890546237\n","Testing Accuracy:  82.11508553654744 %\n","====================\n","Training Loss:  0.451787119866499 Time:  35.846027851104736 s\n","Testing Loss:  0.54365734891458\n","Testing Accuracy:  84.44790046656298 %\n","====================\n","Training Loss:  0.2862397491792968 Time:  35.66173434257507 s\n","Testing Loss:  0.8220403058962389\n","Testing Accuracy:  82.73716951788491 %\n","-\n","THIS IS: e14\n","****************************************\n","N_FILTERS=304 | WIN_SIZES=[2, 6, 4, 8] | DROP=False\n","CNNclass(\n","  (convs): ModuleList(\n","    (0): Sequential(\n","      (0): Conv1d(300, 304, kernel_size=(2,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Conv1d(300, 304, kernel_size=(6,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Conv1d(300, 304, kernel_size=(4,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","    (3): Sequential(\n","      (0): Conv1d(300, 304, kernel_size=(8,), stride=(1,), padding=(2,))\n","      (1): BatchNorm1d(304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU()\n","    )\n","  )\n","  (projection_layer): Linear(in_features=1216, out_features=16, bias=True)\n",") cuda\n","****************************************\n","Training Loss:  0.8248410542089972 Time:  37.71974849700928 s\n","Testing Loss:  0.6278773817149076\n","Testing Accuracy:  78.69362363919129 %\n","====================\n","Training Loss:  0.6143181598632627 Time:  37.171387910842896 s\n","Testing Loss:  0.4519124457781965\n","Testing Accuracy:  86.93623639191291 %\n","====================\n","Training Loss:  0.4525096216501908 Time:  37.00496435165405 s\n","Testing Loss:  0.5202724967490543\n","Testing Accuracy:  81.33748055987559 %\n","e14 has passed the threshold, achieving: 86.93623639191291%\n","-\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"25ZsruJExi2N","colab_type":"code","outputId":"318e84e7-10be-49fe-9f4e-19f6e546170d","executionInfo":{"status":"ok","timestamp":1580882128670,"user_tz":300,"elapsed":1367522,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"11896960355749703790"}},"colab":{"base_uri":"https://localhost:8080/","height":386}},"source":["print(\"Found \" + str(len(ensemble_models)) + \" models that passed the threshold.\")\n","\n","for i, (model, acc, params, path) in enumerate(ensemble_models):\n","    print(\"Model \" + str(i) + \" is \" + str(acc) + \"% accurate.\")\n","    print(\"Model \" + str(i) + \" is saved at: \" + path)\n","    print('-'*20)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Found 7 models that passed the threshold.\n","Model 0 is 85.69206842923795% accurate.\n","Model 0 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e0\n","--------------------\n","Model 1 is 86.31415241057543% accurate.\n","Model 1 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e2\n","--------------------\n","Model 2 is 85.8475894245723% accurate.\n","Model 2 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e4\n","--------------------\n","Model 3 is 85.53654743390358% accurate.\n","Model 3 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e7\n","--------------------\n","Model 4 is 85.53654743390358% accurate.\n","Model 4 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e9\n","--------------------\n","Model 5 is 86.93623639191291% accurate.\n","Model 5 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e12\n","--------------------\n","Model 6 is 86.93623639191291% accurate.\n","Model 6 is saved at: /content/gdrive/My Drive/CNN for Sentence Classification/models4/e14\n","--------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9F_VwVrVpOjg","colab_type":"code","colab":{}},"source":["## majority voting scheme for the ensembled models\n","\n","def ensemble_test(ensemble_models, loader, criterion, device, test=False):\n","    with torch.no_grad():\n","        total_predictions = 0.0\n","        correct_predictions = 0.0\n","        pred = []\n","\n","        for batch_idx, (words, target) in enumerate(loader):   \n","            words = words.to(device)\n","            target = to_tensor(target).to(device)\n","            label_votes = np.zeros(len(classes))\n","            #ensembled_outputs = torch.zeros((target.size(0), len(classes)), device=device)\n","\n","            # Majority voting\n","            for (model, acc, params, path) in ensemble_models:\n","                model.eval()\n","                output = model(words)\n","                _, predicted = torch.max(output.data, 1)\n","                label_votes[predicted.cpu().numpy()[0]] += 1\n","                #ensembled_outputs += model(words)\n","\n","            label = np.argmax(label_votes)\n","            target = target.cpu().numpy()[0]\n","            #_, predicted = torch.max(ensembled_outputs.data, 1)\n","            if not test:\n","                total_predictions += 1\n","                correct_predictions += (label == target)\n","\n","            pred.append(classes[label])\n","\n","        if not test:\n","            acc = (correct_predictions/total_predictions)*100.0\n","            print('Testing Accuracy: ', acc, '%')\n","        return pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1_ch5Xoj8FGg","colab_type":"code","colab":{}},"source":["val_pred_loader_args = dict(shuffle=False, batch_size=1, num_workers=0, pin_memory=True, collate_fn=collate) if cuda\\\n","                    else dict(shuffle=False, batch_size=1, collate_fn=collate)\n","val_pred_loader = data.DataLoader(val_data, **val_pred_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7TAMvO-Syp1B","colab_type":"code","outputId":"f25f9b7d-1611-48b4-9623-9ac116069f60","executionInfo":{"status":"ok","timestamp":1580882133701,"user_tz":300,"elapsed":1367984,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"11896960355749703790"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["predictions = ensemble_test(ensemble_models, val_pred_loader, criterion, device)\n","print(len(predictions), len(val_x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Testing Accuracy:  87.55832037325038 %\n","643 643\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WHR-fQaCzI5B","colab_type":"code","colab":{}},"source":["out_path = root_path + ensemble_group + \"ensembled_val_labels.txt\"\n","with open(out_path, 'w') as f:\n","    for pred in predictions:\n","        f.write(pred+\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnJ3Ailu-2kJ","colab_type":"code","colab":{}},"source":["test_pred_loader_args = dict(shuffle=False, batch_size=1, num_workers=0, pin_memory=True, collate_fn=collate) if cuda\\\n","                    else dict(shuffle=False, batch_size=1, collate_fn=collate)\n","test_pred_loader = data.DataLoader(test_data, **test_pred_loader_args)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgU9FzRm_BQG","colab_type":"code","outputId":"2d6f3222-c9e1-4e1d-96e3-fbbb3060516e","executionInfo":{"status":"ok","timestamp":1580882138798,"user_tz":300,"elapsed":1370929,"user":{"displayName":"Brian Yan","photoUrl":"","userId":"11896960355749703790"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["predictions = ensemble_test(ensemble_models, test_pred_loader, criterion, device, True)\n","print(len(predictions), len(test_x))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["697 697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"POR769Jx_DMT","colab_type":"code","colab":{}},"source":["out_path = root_path + ensemble_group + \"ensembled_test_labels.txt\"\n","with open(out_path, 'w') as f:\n","    for pred in predictions:\n","        f.write(pred+\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BUc2U_QaT0-2","colab_type":"text"},"source":["**GENERATING LABELS**\n","\n","The above ensembling procedure was run 3x, achieving ~88% accuracy each time. Those 3 runs were then combined below with another majority voting procedure. This final ensembling did not change the validation accuracy materially."]},{"cell_type":"code","metadata":{"id":"pfGaMFeecGTk","colab_type":"code","colab":{}},"source":["val_file = \"ensembled_val_labels.txt\"\n","val_files = [root_path+\"/models\"+str(i)+\"/\"+val_file for i in range(1,4)]\n","file_data = {file_name : open(file_name, 'r') for file_name in val_files}\n","\n","with open(root_path + \"/val_labels.txt\", 'w') as out_file:\n","    for row in range(len(val_x)):\n","        label_votes = np.zeros(len(classes))\n","        # Majority vote\n","        for f in file_data.values():\n","            label_votes[class_id(f.readline().strip('\\n'))] += 1\n","        vote_result = np.argmax(label_votes)\n","        out_file.write(classes[vote_result] + '\\n')\n","\n","for f in file_data.values():\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGDaLwnsYE8F","colab_type":"code","colab":{}},"source":["test_file = \"ensembled_test_labels.txt\"\n","test_files = [root_path+\"/models\"+str(i)+\"/\"+test_file for i in range(1,4)]\n","file_data = {file_name : open(file_name, 'r') for file_name in test_files}\n","\n","with open(root_path + \"/test_labels.txt\", 'w') as out_file:\n","    for row in range(len(test_x)):\n","        label_votes = np.zeros(len(classes))\n","        # Majority vote\n","        for f in file_data.values():\n","            label_votes[class_id(f.readline().strip('\\n'))] += 1\n","        vote_result = np.argmax(label_votes)\n","        out_file.write(classes[vote_result] + '\\n')\n","\n","for f in file_data.values():\n","    f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GVFqQKKGc4k9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}